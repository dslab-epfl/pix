diff --git a/drivers/net/ixgbe/ixgbe_rxtx.c b/drivers/net/ixgbe/ixgbe_rxtx.c
index 6fda870..879bb15 100644
--- a/drivers/net/ixgbe/ixgbe_rxtx.c
+++ b/drivers/net/ixgbe/ixgbe_rxtx.c
@@ -344,6 +344,10 @@ tx_xmit_pkts(void *tx_queue, struct rte_mbuf **tx_pkts,
 	rte_wmb();
 	IXGBE_PCI_REG_WRITE_RELAXED(txq->tdt_reg_addr, txq->tx_tail);
 
+#ifdef KLEE_VERIFICATION
+	txq->tx_tail = 0;
+#endif
+
 	return nb_pkts;
 }
 
diff --git a/lib/librte_eal/common/include/arch/x86/rte_cycles.h b/lib/librte_eal/common/include/arch/x86/rte_cycles.h
index 1bb3e1d..c948258 100644
--- a/lib/librte_eal/common/include/arch/x86/rte_cycles.h
+++ b/lib/librte_eal/common/include/arch/x86/rte_cycles.h
@@ -48,41 +48,49 @@ extern int rte_cycles_vmware_tsc_map;
 #endif
 #include <rte_common.h>
 
+#ifdef KLEE_VERIFICATION
+uint64_t
+rte_rdtsc(void);
+
+uint64_t
+rte_rdtsc_precise(void);
+#else//KLEE_VERIFICATION
 static inline uint64_t
 rte_rdtsc(void)
 {
-	union {
-		uint64_t tsc_64;
-		RTE_STD_C11
-		struct {
-			uint32_t lo_32;
-			uint32_t hi_32;
-		};
-	} tsc;
+       union {
+               uint64_t tsc_64;
+               RTE_STD_C11
+               struct {
+                       uint32_t lo_32;
+                       uint32_t hi_32;
+               };
+       } tsc;
 
 #ifdef RTE_LIBRTE_EAL_VMWARE_TSC_MAP_SUPPORT
-	if (unlikely(rte_cycles_vmware_tsc_map)) {
-		/* ecx = 0x10000 corresponds to the physical TSC for VMware */
-		asm volatile("rdpmc" :
-		             "=a" (tsc.lo_32),
-		             "=d" (tsc.hi_32) :
-		             "c"(0x10000));
-		return tsc.tsc_64;
-	}
+       if (unlikely(rte_cycles_vmware_tsc_map)) {
+               /* ecx = 0x10000 corresponds to the physical TSC for VMware */
+               asm volatile("rdpmc" :
+                            "=a" (tsc.lo_32),
+                            "=d" (tsc.hi_32) :
+                            "c"(0x10000));
+               return tsc.tsc_64;
+       }
 #endif
 
-	asm volatile("rdtsc" :
-		     "=a" (tsc.lo_32),
-		     "=d" (tsc.hi_32));
-	return tsc.tsc_64;
+       asm volatile("rdtsc" :
+                    "=a" (tsc.lo_32),
+                    "=d" (tsc.hi_32));
+       return tsc.tsc_64;
 }
 
 static inline uint64_t
 rte_rdtsc_precise(void)
 {
-	rte_mb();
-	return rte_rdtsc();
+       rte_mb();
+       return rte_rdtsc();
 }
+#endif//KLEE_VERIFICATION
 
 static inline uint64_t
 rte_get_tsc_cycles(void) { return rte_rdtsc(); }
diff --git a/lib/librte_eal/common/include/arch/x86/rte_memcpy.h b/lib/librte_eal/common/include/arch/x86/rte_memcpy.h
index 74c280c..b2f84d8 100644
--- a/lib/librte_eal/common/include/arch/x86/rte_memcpy.h
+++ b/lib/librte_eal/common/include/arch/x86/rte_memcpy.h
@@ -65,8 +65,13 @@ extern "C" {
  * @return
  *   Pointer to the destination data.
  */
+#ifdef KLEE_VERIFICATION
+void *
+rte_memcpy(void *dst, const void *src, size_t n);
+#else//KLEE_VERIFICATION
 static __rte_always_inline void *
 rte_memcpy(void *dst, const void *src, size_t n);
+#endif//KLEE_VERIFICATION
 
 #ifdef RTE_MACHINE_CPUFLAG_AVX512F
 
@@ -888,17 +893,21 @@ rte_memcpy_aligned(void *dst, const void *src, size_t n)
 	return ret;
 }
 
+#ifndef KLEE_VERIFICATION
 static inline void *
 rte_memcpy(void *dst, const void *src, size_t n)
 {
-	if (!(((uintptr_t)dst | (uintptr_t)src) & ALIGNMENT_MASK))
-		return rte_memcpy_aligned(dst, src, n);
-	else
-		return rte_memcpy_generic(dst, src, n);
+       if (!(((uintptr_t)dst | (uintptr_t)src) & ALIGNMENT_MASK))
+               return rte_memcpy_aligned(dst, src, n);
+       else
+               return rte_memcpy_generic(dst, src, n);
 }
+#endif//!KLEE_VERIFICATION
 
 #ifdef __cplusplus
 }
 #endif
 
 #endif /* _RTE_MEMCPY_X86_64_H_ */
+
+ 
diff --git a/lib/librte_eal/common/include/arch/x86/rte_prefetch.h b/lib/librte_eal/common/include/arch/x86/rte_prefetch.h
index f464398..fffe630 100644
--- a/lib/librte_eal/common/include/arch/x86/rte_prefetch.h
+++ b/lib/librte_eal/common/include/arch/x86/rte_prefetch.h
@@ -41,25 +41,34 @@ extern "C" {
 #include <rte_common.h>
 #include "generic/rte_prefetch.h"
 
+#ifdef KLEE_VERIFICATION
+void rte_prefetch0(const volatile void *p);
+
+void rte_prefetch1(const volatile void *p);
+
+void rte_prefetch2(const volatile void *p);
+
+void rte_prefetch_non_temporal(const volatile void *p);
+#else//KLEE_VERIFICATION
 static inline void rte_prefetch0(const volatile void *p)
 {
-	asm volatile ("prefetcht0 %[p]" : : [p] "m" (*(const volatile char *)p));
+       asm volatile ("prefetcht0 %[p]" : : [p] "m" (*(const volatile char *)p));
 }
 
 static inline void rte_prefetch1(const volatile void *p)
 {
-	asm volatile ("prefetcht1 %[p]" : : [p] "m" (*(const volatile char *)p));
+       asm volatile ("prefetcht1 %[p]" : : [p] "m" (*(const volatile char *)p));
 }
-
 static inline void rte_prefetch2(const volatile void *p)
 {
-	asm volatile ("prefetcht2 %[p]" : : [p] "m" (*(const volatile char *)p));
+       asm volatile ("prefetcht2 %[p]" : : [p] "m" (*(const volatile char *)p));
 }
 
 static inline void rte_prefetch_non_temporal(const volatile void *p)
 {
-	asm volatile ("prefetchnta %[p]" : : [p] "m" (*(const volatile char *)p));
+       asm volatile ("prefetchnta %[p]" : : [p] "m" (*(const volatile char *)p));
 }
+#endif//KLEE_VERIFICATION
 
 #ifdef __cplusplus
 }
diff --git a/lib/librte_eal/common/include/generic/rte_prefetch.h b/lib/librte_eal/common/include/generic/rte_prefetch.h
index 07e409e..9d59c21 100644
--- a/lib/librte_eal/common/include/generic/rte_prefetch.h
+++ b/lib/librte_eal/common/include/generic/rte_prefetch.h
@@ -34,6 +34,12 @@
 #ifndef _RTE_PREFETCH_H_
 #define _RTE_PREFETCH_H_
 
+#ifdef KLEE_VERIFICATION
+#define STATIC
+#else//KLEE_VERIFICATION
+#define STATIC static inline
+#endif//KLEE_VERIFICATION
+
 /**
  * @file
  *
@@ -51,14 +57,14 @@
  * @param p
  *   Address to prefetch
  */
-static inline void rte_prefetch0(const volatile void *p);
+STATIC void rte_prefetch0(const volatile void *p);
 
 /**
  * Prefetch a cache line into all cache levels except the 0th cache level.
  * @param p
  *   Address to prefetch
  */
-static inline void rte_prefetch1(const volatile void *p);
+STATIC void rte_prefetch1(const volatile void *p);
 
 /**
  * Prefetch a cache line into all cache levels except the 0th and 1th cache
@@ -66,7 +72,7 @@ static inline void rte_prefetch1(const volatile void *p);
  * @param p
  *   Address to prefetch
  */
-static inline void rte_prefetch2(const volatile void *p);
+STATIC void rte_prefetch2(const volatile void *p);
 
 /**
  * Prefetch a cache line into all cache levels (non-temporal/transient version)
@@ -78,6 +84,6 @@ static inline void rte_prefetch2(const volatile void *p);
  * @param p
  *   Address to prefetch
  */
-static inline void rte_prefetch_non_temporal(const volatile void *p);
+STATIC void rte_prefetch_non_temporal(const volatile void *p);
 
 #endif /* _RTE_PREFETCH_H_ */
diff --git a/lib/librte_hash/rte_cmp_arm64.h b/lib/librte_hash/rte_cmp_arm64.h
index 950cef3..cb49e94 100644
--- a/lib/librte_hash/rte_cmp_arm64.h
+++ b/lib/librte_hash/rte_cmp_arm64.h
@@ -36,21 +36,27 @@ static int
 rte_hash_k16_cmp_eq(const void *key1, const void *key2,
 		    size_t key_len __rte_unused)
 {
-	uint64_t x0, x1, y0, y1;
+#ifdef KLEE_VERIFICATION
+       uint64_t *x = key1,
+                *y = key2;
+       return *x == *y && *(x+1) == *(y+1);
+#else//KLEE_VERIFICATION
+       uint64_t x0, x1, y0, y1;
 
-	asm volatile(
-		"ldp %x[x1], %x[x0], [%x[p1]]"
-		: [x1]"=r"(x1), [x0]"=r"(x0)
-		: [p1]"r"(key1)
-		);
-	asm volatile(
-		"ldp %x[y1], %x[y0], [%x[p2]]"
-		: [y1]"=r"(y1), [y0]"=r"(y0)
-		: [p2]"r"(key2)
-		);
-	x0 ^= y0;
-	x1 ^= y1;
-	return !(x0 == 0 && x1 == 0);
+       asm volatile(
+               "ldp %x[x1], %x[x0], [%x[p1]]"
+               : [x1]"=r"(x1), [x0]"=r"(x0)
+               : [p1]"r"(key1)
+               );
+       asm volatile(
+               "ldp %x[y1], %x[y0], [%x[p2]]"
+               : [y1]"=r"(y1), [y0]"=r"(y0)
+               : [p2]"r"(key2)
+               );
+       x0 ^= y0;
+       x1 ^= y1;
+       return !(x0 == 0 && x1 == 0);
+#endif//KLEE_VERIFICATION
 }
 
 static int
diff --git a/lib/librte_hash/rte_cmp_x86.h b/lib/librte_hash/rte_cmp_x86.h
index 704c2de..4f332f5 100644
--- a/lib/librte_hash/rte_cmp_x86.h
+++ b/lib/librte_hash/rte_cmp_x86.h
@@ -35,11 +35,16 @@
 static int
 rte_hash_k16_cmp_eq(const void *key1, const void *key2, size_t key_len __rte_unused)
 {
-	const __m128i k1 = _mm_loadu_si128((const __m128i *) key1);
-	const __m128i k2 = _mm_loadu_si128((const __m128i *) key2);
-	const __m128i x = _mm_xor_si128(k1, k2);
+#ifdef KLEE_VERIFICATION
+       const uint64_t *x = key1, *y = key2;
+       return *x == *y && *(x+1) == *(y+1);
+#else//KLEE_VERIFICATION
+       const __m128i k1 = _mm_loadu_si128((const __m128i *) key1);
+       const __m128i k2 = _mm_loadu_si128((const __m128i *) key2);
+       const __m128i x = _mm_xor_si128(k1, k2);
 
-	return !_mm_test_all_zeros(x, x);
+       return !_mm_test_all_zeros(x, x);
+#endif//KLEE_VERIFICATION
 }
 
 static int
diff --git a/lib/librte_hash/rte_thash.h b/lib/librte_hash/rte_thash.h
index 4fa5e07..3c2a714 100644
--- a/lib/librte_hash/rte_thash.h
+++ b/lib/librte_hash/rte_thash.h
@@ -169,18 +169,18 @@ rte_convert_rss_key(const uint32_t *orig, uint32_t *targ, int len)
 static inline void
 rte_thash_load_v6_addrs(const struct ipv6_hdr *orig, union rte_thash_tuple *targ)
 {
-#ifdef RTE_ARCH_X86
-	__m128i ipv6 = _mm_loadu_si128((const __m128i *)orig->src_addr);
-	*(__m128i *)targ->v6.src_addr =
-			_mm_shuffle_epi8(ipv6, rte_thash_ipv6_bswap_mask);
-	ipv6 = _mm_loadu_si128((const __m128i *)orig->dst_addr);
-	*(__m128i *)targ->v6.dst_addr =
-			_mm_shuffle_epi8(ipv6, rte_thash_ipv6_bswap_mask);
-#elif defined(RTE_MACHINE_CPUFLAG_NEON)
-	uint8x16_t ipv6 = vld1q_u8((uint8_t const *)orig->src_addr);
-	vst1q_u8((uint8_t *)targ->v6.src_addr, vrev32q_u8(ipv6));
-	ipv6 = vld1q_u8((uint8_t const *)orig->dst_addr);
-	vst1q_u8((uint8_t *)targ->v6.dst_addr, vrev32q_u8(ipv6));
+#if defined(RTE_ARCH_X86) && !defined(KLEE_VERIFICATION)
+       __m128i ipv6 = _mm_loadu_si128((const __m128i *)orig->src_addr);
+       *(__m128i *)targ->v6.src_addr =
+                       _mm_shuffle_epi8(ipv6, rte_thash_ipv6_bswap_mask);
+       ipv6 = _mm_loadu_si128((const __m128i *)orig->dst_addr);
+       *(__m128i *)targ->v6.dst_addr =
+                       _mm_shuffle_epi8(ipv6, rte_thash_ipv6_bswap_mask);
+#elif defined(RTE_MACHINE_CPUFLAG_NEON) && !defined(KLEE_VERIFICATION)
+       uint8x16_t ipv6 = vld1q_u8((uint8_t const *)orig->src_addr);
+       vst1q_u8((uint8_t *)targ->v6.src_addr, vrev32q_u8(ipv6));
+       ipv6 = vld1q_u8((uint8_t const *)orig->dst_addr);
+       vst1q_u8((uint8_t *)targ->v6.dst_addr, vrev32q_u8(ipv6));
 #else
 	int i;
 	for (i = 0; i < 4; i++) {
diff --git a/lib/librte_table/rte_lru.h b/lib/librte_table/rte_lru.h
index 88229d8..afd5916 100644
--- a/lib/librte_table/rte_lru.h
+++ b/lib/librte_table/rte_lru.h
@@ -10,9 +10,9 @@ extern "C" {
 #endif
 
 #include <rte_config.h>
-#ifdef RTE_ARCH_X86_64
+#if defined(RTE_ARCH_X86_64) && !defined(KLEE_VERIFICATION)
 #include "rte_lru_x86.h"
-#elif defined(RTE_ARCH_ARM64)
+#elif defined(RTE_ARCH_ARM64) && !defined(KLEE_VERIFICATION)
 #include "rte_lru_arm64.h"
 #else
 #undef RTE_TABLE_HASH_LRU_STRATEGY
